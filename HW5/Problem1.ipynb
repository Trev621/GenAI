{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOdGFsPAHbIWmxCwde9G1AZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trev621/GenAI/blob/main/HW5/Problem1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Author: Trevor Lacoste\n",
        "The purpose of this assignment is to develop an LSTM (Long Short-Term Memory) model to generate text."
      ],
      "metadata": {
        "id": "r66ThXgPVAOY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C7gKGYl2UrPY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, losses\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ],
      "metadata": {
        "id": "66fgv1gTVQwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 10000\n",
        "MAX_LEN = 200\n",
        "EMBEDDING_DIM = 100\n",
        "N_UNITS = 128\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 75"
      ],
      "metadata": {
        "id": "daMXjL4TUuqb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection and Preparation"
      ],
      "metadata": {
        "id": "ud7I3WWGVWDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "#List of URLs for additional texts (e.g., different Shakespeare plays)\n",
        "urls = [\n",
        "  \"https://www.gutenberg.org/files/1041/1041-0.txt\",  #Hamlet\n",
        "  \"https://www.gutenberg.org/files/152/152-0.txt\",   #Macbeth\n",
        "  \"https://www.gutenberg.org/files/1112/1112-0.txt\"   #Othello\n",
        "]\n",
        "\n",
        "#Initialize an empty string to hold all text\n",
        "all_text = \"\"\n",
        "\n",
        "#Download each text file and append to all_text\n",
        "for url in urls:\n",
        "  response = requests.get(url)\n",
        "  text = response.text\n",
        "  all_text += text + \"\\n\\n\"  #Separate texts by newlines\n",
        "\n",
        "#Save combined text to a single file\n",
        "with open(\"combined_shakespeare.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "  file.write(all_text)"
      ],
      "metadata": {
        "id": "aaDTyfbZUusx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    #Remove the header and footer\n",
        "    start_index = text.find('*** START OF THIS PROJECT GUTENBERG EBOOK')\n",
        "    end_index = text.find('*** END OF THIS PROJECT GUTENBERG EBOOK')\n",
        "    if start_index != -1 and end_index != -1:\n",
        "        text = text[start_index:end_index]\n",
        "\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  #Remove non-letter characters\n",
        "    text = text.lower()  #Convert text to lowercase\n",
        "    return text\n",
        "\n",
        "cleaned_text = preprocess_text(all_text)\n",
        "\n",
        "#Tokenization\n",
        "tokens = cleaned_text.split() #Split the text into words (tokens)"
      ],
      "metadata": {
        "id": "Pb4WNAKgUuu5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to a Tensorflow Dataset\n",
        "text_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(tokens)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .shuffle(1000)\n",
        ")"
      ],
      "metadata": {
        "id": "rd3UXvlIUuxA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a vectorisation layer\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=\"lower\",\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=MAX_LEN + 1,\n",
        ")"
      ],
      "metadata": {
        "id": "pUAXq-00UuzB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adapt the layer to the training set\n",
        "vectorize_layer.adapt(text_ds)\n",
        "vocab = vectorize_layer.get_vocabulary()"
      ],
      "metadata": {
        "id": "QS5pjpxKUu0-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the training set, shifted by one word\n",
        "def prepare_inputs(text):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    tokenized_sentences = vectorize_layer(text)\n",
        "    x = tokenized_sentences[:, :-1]  #Input sequence\n",
        "    y = tokenized_sentences[:, -1]   #Predict next word\n",
        "    return x, y\n",
        "\n",
        "train_ds = text_ds.map(prepare_inputs)"
      ],
      "metadata": {
        "id": "KVzo7VciUu2v"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Baseline Model"
      ],
      "metadata": {
        "id": "sB-qWGLI0F8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#One layer LSTM model\n",
        "inputs_base = layers.Input(shape=(None,), dtype=\"int32\")  #Input layer\n",
        "\n",
        "x_base = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM)(inputs_base) #Embedding layer\n",
        "\n",
        "x_base = layers.LSTM(N_UNITS)(x_base) #LSTM layer\n",
        "\n",
        "outputs_base = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x_base) #Output layer\n",
        "\n",
        "base_lstm = models.Model(inputs_base, outputs_base)\n",
        "base_lstm.summary() #Model summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "aYZ5LaKY0JyZ",
        "outputId": "75567ee1-b0c9-4ed8-9925-2d2f8d0583c9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │       \u001b[38;5;34m1,000,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m117,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10000\u001b[0m)               │       \u001b[38;5;34m1,290,000\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290,000</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,407,248\u001b[0m (9.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,407,248</span> (9.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,407,248\u001b[0m (9.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,407,248</span> (9.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling base model\n",
        "loss_base = losses.SparseCategoricalCrossentropy()\n",
        "base_lstm.compile(\"adam\", loss_base)"
      ],
      "metadata": {
        "id": "eEClnJUX0KIc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training base model\n",
        "base_lstm.fit(\n",
        "    train_ds,\n",
        "    epochs=50\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrWmzZjq1iHv",
        "outputId": "b750f020-a75b-4842-ddaf-39165e030223"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.6928\n",
            "Epoch 2/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 2.6170e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 8.0717e-05\n",
            "Epoch 4/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 3.3741e-05\n",
            "Epoch 5/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 1.5854e-05\n",
            "Epoch 6/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 7.8839e-06\n",
            "Epoch 7/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - loss: 4.0791e-06\n",
            "Epoch 8/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - loss: 2.1749e-06\n",
            "Epoch 9/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 1.1919e-06\n",
            "Epoch 10/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 6.2380e-07\n",
            "Epoch 11/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 3.4218e-07\n",
            "Epoch 12/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 2.0951e-07\n",
            "Epoch 13/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 1.1920e-07\n",
            "Epoch 14/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 1.8370e-09\n",
            "Epoch 15/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 16/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 17/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 18/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 19/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 20/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 21/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 22/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - loss: 0.0000e+00\n",
            "Epoch 23/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 24/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 25/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 26/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 27/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0000e+00\n",
            "Epoch 28/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 29/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 30/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - loss: 0.0000e+00\n",
            "Epoch 31/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 32/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 33/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 34/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 35/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 36/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 37/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 38/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 39/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 40/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - loss: 0.0000e+00\n",
            "Epoch 41/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 42/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 43/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 44/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - loss: 0.0000e+00\n",
            "Epoch 45/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 46/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0000e+00\n",
            "Epoch 47/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 48/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 49/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n",
            "Epoch 50/50\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ae4fe552e90>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed, model, vectorize_layer, vocab, temperature, max_length=100):\n",
        "    for _ in range(max_length):\n",
        "        #Convert the seed to tokenized numbers\n",
        "        tokenized_input = vectorize_layer([seed])\n",
        "        #Predict next word probabilities\n",
        "        predictions = model.predict(tokenized_input, verbose=0)\n",
        "        logits = predictions[0, :]  #For 2D output\n",
        "\n",
        "        scaled_logits = logits / temperature #Apply temp scaling\n",
        "        probabilities = tf.nn.softmax(scaled_logits).numpy()\n",
        "\n",
        "        #Ensure valid sampling within vocab range\n",
        "        next_word_index = np.random.choice(len(probabilities), p=probabilities)\n",
        "        if next_word_index >= len(vocab):\n",
        "            next_word_index = len(vocab) - 1\n",
        "\n",
        "        #Get the next word and add it to the seed\n",
        "        next_word = vocab[next_word_index]\n",
        "        if next_word == \"\":  #If empty, continue\n",
        "            continue\n",
        "        seed += \" \" + next_word\n",
        "\n",
        "    return seed"
      ],
      "metadata": {
        "id": "DG1eBJMUU6o6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample prompts\n",
        "prompts = [\n",
        "    \"To be, or not to be\",\n",
        "    \"Shall I compare thee to a summer's day\",\n",
        "    \"All the world's a stage\"\n",
        "]\n",
        "\n",
        "temperatures = [0.1, 0.5, 1.0]\n",
        "\n",
        "#Test output for each prompt with varying temperatures\n",
        "for prompt in prompts:\n",
        "    print(f\"\\nPrompt: {prompt}\")\n",
        "    for temp in temperatures:\n",
        "        generated_text = generate_text(prompt, base_lstm, vectorize_layer, vocab, temperature=temp)\n",
        "        print(f\"\\nTemperature {temp}:\\n{generated_text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCnRfYlZ1iJ9",
        "outputId": "b02b49be-7efe-4bb2-ab6f-aed3fd366ed8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prompt: To be, or not to be\n",
            "\n",
            "Temperature 0.1:\n",
            "To be, or not to be willing widowd abate shamed wine abate spring toile abate abate legions these shady goarie abate asked abate abate abate abate abate struck fell booke heartlesse respects abate abate juliet abate thinkest abate impiety hrefpolicytermsofusehtmlterms abate abate blots abate abate selfdoing worst abate abate wring goose feet\n",
            "\n",
            "Temperature 0.5:\n",
            "To be, or not to be abate abate angell hairs abate theeuish form abate feed abate abate orecouered fortunes weeps abate shoomaker language abate true ah much surly hall enjoyer hoares abate abate abate white beg beautious immortal excesse abate happlie abate abate crossd abate abate abate abate acted diseasd mousehunt goodness lxiii abate abate abate liud abate abate tarrie abate abate abate abate offend stayd abate perilous fruite according abate abate liuer abate anticipate abate diuers whereupon abate abate abate push goddess cut abroad arrest hath vnhallowed xxxii abate abate consortst notice loathsome face argues abate abate summers abate cozins abate abate abate abate den\n",
            "\n",
            "Temperature 1.0:\n",
            "To be, or not to be hrefpolicypermissionhtmlpermissions quinces douefeatherd abate sees black gord romeo far compile beck misprision points abate worst abate abate abate render abate typehidden childhood abate titleproject abate abate abate pleading abate excuses where enclose abate present abate wanton abate sworne shore abate chiding figurd happlie rosy abate ioyfull tabindex reproving abate abate waves contact afresh figure abate abate selues more everfixed legions draind wane abate minstrels constancy much abate dym smallest stelld beside seekes inherit reeks impatient abate newfired abate abate fa abate forerun followed hrefebookssearch pilcher steepy dial quarell prophetic friers abate seuering wormewood worlds youngest gouernd abate abate devour cxlii\n",
            "\n",
            "Prompt: Shall I compare thee to a summer's day\n",
            "\n",
            "Temperature 0.1:\n",
            "Shall I compare thee to a summer's day displeasure abate abate on thigh abate carefull abate abate abate abate classnohover wights abate posting abate hrefpolicytermsofusehtml nephew abate abate abate abate violently sinks abate slip restore abate wombe\n",
            "\n",
            "Temperature 0.5:\n",
            "Shall I compare thee to a summer's day abate beauties abate bounty abate abate wail oertake increasing abate baggage mard abate most keep abate inuite abate abate abate losses seigneur forbidden commits ride abate iniquity abate abate swallowed brought valour practise abate speak suted abate abate masters plot ones abate decease building lively skaring safety abate abate greene abate change daughter abate abate abate fishified abate mouths effectually denie maruelous quiuers abate beautifie blesses abate abate abate prevent abate exceed importund withal abate dully abate abate given abate mouth abate kin abate abate abate furie polishd wherever dignified contentproject abate abate seale gapes abate abate abate abate me\n",
            "\n",
            "Temperature 1.0:\n",
            "Shall I compare thee to a summer's day offence image cinthias surfeit abate abate abate abate abate renew sacke purblind abate abate abate abate abate graven abate abate abate abate attending abate forme abate eves lap agoe brother prefixed startles whoeer iour debarred shed iawes valours search brotherhood merrily outcast claps unthrifty stifled abate dulness mayst equipage seasons maria guiltie courteous growing spight despite abate proves keep abate abate abate iust abate lately neere confines finis bells predicament abate hag abate abate pebbled abate tomb abate abate mannerly abate abate dreame abate beautious abate continual abate abate continue abate famoused abate abate abate extremity flowers agoe abate youth\n",
            "\n",
            "Prompt: All the world's a stage\n",
            "\n",
            "Temperature 0.1:\n",
            "All the world's a stage brood lath trees toes tributarie dyre keen weand abate partisons abate abate cherishing yours abate flowres displant iphone abate accustomd abate abate abate butshaft abate lark exchangd knaue abate nearly\n",
            "\n",
            "Temperature 0.5:\n",
            "All the world's a stage ranks victor abate abate abate abate abate vnder delves abate pleased do abate imprint prayers age despised abate abate defeated strangle abate abate matter desire abate legions abate bodys abate burden dash excesse things abate abate badness homely abate unthrifts abate abate orchard posteritie lawyers ioyes abate foote pmaybe abate intended abate philomel abate venge rests abate abate graycoated abate curls abate tender bleedes abate becomed murtherer guard hare abate abate violl rich learnt disdain abate diuideth eloquence careful abate brief advocate mansion abate crowning abate satire sweeter abate ladyes endeared abate abate wield abate abate deceast cxli refusest abate\n",
            "\n",
            "Temperature 1.0:\n",
            "All the world's a stage abate indigest abate abate besmeard falkners abate misgiues abate spie cheekes jaws early smoke abate reasons abate abate abate abate silken abate abate strained abate clubs wanderst partly srcpicsenusgif enjoyer abate abate furie lowd bosomes wondrous poultis preventst pleasure heauy abate sportive visor abate prone breach sharp wing abate abate muse shows abate ruld flourishes creating input abate befriends abate hrefhelpmobilehtmltablets abate abate yellow contenthttpswwwgutenbergorggutenbergpglogoxpng clear invited already abate abate abate disposition abate peep abate abate abate titleabout courts stretched pet clearer knowne glass babe abate abate odde drowsie hunting abate vncouerd abundant wastes abate bud truths abate herd abate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "9yRjY7FNA9D6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The basic LSTM, with one layer, trained in about half of the time of more complex LSTM. The results with 50 epochs and only layer are better than expected, although there are still clear issues with the model. It is able to generate a variety of different words, but some of the words like \"carefull\" are mispelled and other words like, \"douefeatherd\" seem to be made up. Another clear issue with this model is that the word \"abate\" seems to get repeated a lot. So overall, the model has a very basic idea of the words that Shakespeare uses. As for the style, none of the phrases really make sense. The words seem to be randomly ordered. To improve on the coherence and style, the model needs a lot more training."
      ],
      "metadata": {
        "id": "pMhH_Dtv2tkO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Model & Training"
      ],
      "metadata": {
        "id": "maxDesqDVegR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(None,), dtype=\"int32\") #Input layer\n",
        "\n",
        "x = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM)(inputs) #Embedding layer\n",
        "\n",
        "x = layers.LSTM(N_UNITS, return_sequences=True)(x) #First LSTM layer\n",
        "x = layers.LSTM(N_UNITS, return_sequences=True)(x) #Second LstM layer\n",
        "x = layers.LSTM(N_UNITS)(x) #Last LSTM Layer\n",
        "\n",
        "outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x) #Output layer\n",
        "\n",
        "lstm = models.Model(inputs, outputs)\n",
        "lstm.summary() #Model summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "L-hxIdPQUu43",
        "outputId": "2324a43c-c550-4211-9b3f-612a1a265c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │       \u001b[38;5;34m1,000,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m117,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10000\u001b[0m)               │       \u001b[38;5;34m1,290,000\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290,000</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,670,416\u001b[0m (10.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,670,416</span> (10.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,670,416\u001b[0m (10.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,670,416</span> (10.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = losses.SparseCategoricalCrossentropy()\n",
        "lstm.compile(\"adam\", loss_fn) #Compile the LSTM"
      ],
      "metadata": {
        "id": "eYwiSbUIUu8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training LSTM\n",
        "lstm.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUKnmRRGU6nE",
        "outputId": "06b9a68b-a066-4852-a31d-747e7743e7bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - loss: 0.6949\n",
            "Epoch 2/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 24ms/step - loss: 2.6220e-04\n",
            "Epoch 3/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 24ms/step - loss: 8.0888e-05\n",
            "Epoch 4/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 24ms/step - loss: 3.3863e-05\n",
            "Epoch 5/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 1.5956e-05\n",
            "Epoch 6/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 7.9517e-06\n",
            "Epoch 7/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 4.1216e-06\n",
            "Epoch 8/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 2.1962e-06\n",
            "Epoch 9/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - loss: 1.2028e-06\n",
            "Epoch 10/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - loss: 6.2772e-07\n",
            "Epoch 11/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 24ms/step - loss: 3.4273e-07\n",
            "Epoch 12/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 2.1002e-07\n",
            "Epoch 13/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 1.1921e-07\n",
            "Epoch 14/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 3.3483e-09\n",
            "Epoch 15/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 16/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 17/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 24ms/step - loss: 0.0000e+00\n",
            "Epoch 18/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 24ms/step - loss: 0.0000e+00\n",
            "Epoch 19/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 20/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - loss: 0.0000e+00\n",
            "Epoch 21/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 22/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 23/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 24/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 25/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 26/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 27/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 28/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 29/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - loss: 0.0000e+00\n",
            "Epoch 30/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 31/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 24ms/step - loss: 0.0000e+00\n",
            "Epoch 32/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 33/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 34/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 35/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 24ms/step - loss: 0.0000e+00\n",
            "Epoch 36/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 37/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 38/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 39/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 40/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 41/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 42/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 43/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 24ms/step - loss: 0.0000e+00\n",
            "Epoch 44/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 45/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 46/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 47/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 24ms/step - loss: 0.0000e+00\n",
            "Epoch 48/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 49/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 50/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 51/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 52/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 53/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 54/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 55/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 56/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 24ms/step - loss: 0.0000e+00\n",
            "Epoch 57/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 58/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 59/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 60/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 61/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 62/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 63/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 64/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 65/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 24ms/step - loss: 0.0000e+00\n",
            "Epoch 66/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 67/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 68/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 69/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 70/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 71/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 72/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 73/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 23ms/step - loss: 0.0000e+00\n",
            "Epoch 74/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 24ms/step - loss: 0.0000e+00\n",
            "Epoch 75/75\n",
            "\u001b[1m1353/1353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 24ms/step - loss: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ab184ec6c20>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Temperature and Prompt Variations"
      ],
      "metadata": {
        "id": "DcHdn0GfWCAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample prompts\n",
        "prompts = [\n",
        "    \"To be, or not to be\",\n",
        "    \"Shall I compare thee to a summer's day\",\n",
        "    \"All the world's a stage\"\n",
        "]\n",
        "\n",
        "temperatures = [0.1, 0.5, 1.0]\n",
        "\n",
        "#Test output for each prompt with varying temperatures\n",
        "for prompt in prompts:\n",
        "    print(f\"\\nPrompt: {prompt}\")\n",
        "    for temp in temperatures:\n",
        "        generated_text = generate_text(prompt, lstm, vectorize_layer, vocab, temperature=temp)\n",
        "        print(f\"\\nTemperature {temp}:\\n{generated_text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62yH5Uy6U6rC",
        "outputId": "f370cdd8-982f-4bae-8edd-040fb1a52229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prompt: To be, or not to be\n",
            "\n",
            "Temperature 0.1:\n",
            "To be, or not to be lath waxe richer abate cvi largess snow widowed loe retire abate ready abate abate abate abate abate meete water abate cozins replete abate linger cheuerell nourishd exchange cheares briefly abate sale uneard godgigoden abate\n",
            "\n",
            "Temperature 0.5:\n",
            "To be, or not to be francis abate abate displant abate orecouered earthquake christian argues fall wenches abate abate woos abate abate stand injury yeares steeld pencil abate abate chaunces abate abate afflicted abate abate curls ghostly read threatned abate abate sings murderous abate messenger enctypemultipartformdata propertyogtitle ground seemd abate suffers canons godden abate abate abate performe heartinflaming center seene abate abate abate lamentable abate abate abate fountaines harmful hated abate mind abate gloue value step abate arithmeticke abate miscarried streaks abate abate hrefebookssearch husbandry estate abate abate abate cozen pays niggarding abate filching abate xcviii input abate on namehostedbuttonid mountagues comforted grow widows destroys abate\n",
            "\n",
            "Temperature 1.0:\n",
            "To be, or not to be simon abate viewest abate quill serving harvest pilgrim blesses abate begin repose abate abate abate depends classsubmenu kin lilys abate abate depart abate society none abate despair hist classpagecontent sinks xxiii abate abate abate dressings few forme forgetful entertained tongue abate sweetseasond lxxxix merchant abate follower title abate abate cats marjoram abate enclose abate diest night abate cause grones driueling knowes something abate saies thief creatures herself abate autumn geare staid brain junes fetch fickle abate abate chose look birds workings vilest loathed darknesse new may blessedfair shady abate dumb substance abate abate la serue abate just abate saue abate\n",
            "\n",
            "Prompt: Shall I compare thee to a summer's day\n",
            "\n",
            "Temperature 0.1:\n",
            "Shall I compare thee to a summer's day windswift style abate beautifie merits manies keies rereward fond abate wait affright closely abate abate aye befits aquavitae allow abate graciously clii curphew light abate abate bright complement suted abate colour\n",
            "\n",
            "Temperature 0.5:\n",
            "Shall I compare thee to a summer's day argument abate fearfully abate case fray abate mu trifling hilding adjunct sets abate subiect abate successive abate hoope religion marchandise abate impregnable vnbound shrike vows abate vnto abate typetext abate tear cxxxii expire xxxi top abate shall presage h sourest along abate cheere purblind mongers abate abate abate abate selfloving abate abate abate halfe abate abate abate counterfait abate nought father servants autumn mind developmentali abate confound idolatry alacke paine clothes center prie active truce itch obsequious abate tempt remote surfeit abate kisses abate vex abate sourly disease throw had abate phoenix abate travels abate hounds abate bumpe abate abate\n",
            "\n",
            "Temperature 1.0:\n",
            "Shall I compare thee to a summer's day cleare just thred ake abate huge abate abate tonguetied abate abate fals unfolding doth reuolt permit compard married rightly abate abate valuesxclick anything abate hrefaboutcontactinformationhtml bold abate abate dwellers render ambling abate begger orecouered itch abate abate nurse boldness withering abate abate rich abate xxxvi separation battlements tooke feele abate abate wealth forgetst abate hooks licenseali abate abate stirrd abate prouision atomies vpon plagues sunken cracking abate abate request abate very secret surfeit says abate simon abate abate abate complain learnt martiall tying enjoyd feeling knocke abate abate abate fickle rote wantons abate imaginary maskd often abate goodmorrow mischiefe reckon\n",
            "\n",
            "Prompt: All the world's a stage\n",
            "\n",
            "Temperature 0.1:\n",
            "All the world's a stage abate talkst abate abate browse examine abate semblance remaine violet holydam passado situation cxl keepst abate abate boast runst vile ceremony abate pennes angels hoisted office madman tearmes attires sets aduenture abate beginners abate lace learneds windy\n",
            "\n",
            "Temperature 0.5:\n",
            "All the world's a stage knaue abate abate abate abate consumd loggerhead ynch golden iust cxix abate abate plainly bird debtor shoot others bears altibiblio downright rauenous abate abate silent pitied abate freetowne abate common linger xciii chearely statute afore wings abate abate abate abate graces abate abate restful traces abate wise abate rapiers submissionali died gross intermixd skuruy readie succeeding urge abate posterity abate deaw abate abate sufferd abate classdonbtn dispense abate abate amorous abate abate warmd abate abate spending shalt ha scope abate abate correction abate compound lath abate juliet aboard strive abate brow abate abate ancient pluck ore abate ripe abate abate\n",
            "\n",
            "Temperature 1.0:\n",
            "All the world's a stage abate dog abate initialscale iealous brest prayers sepulchres dirltr abate pursued house seruant abate ere xcvi abate abate abate forehead contact fly abate culling reeleth saist abate falne abate hope foes abate penury abate liii abate bare abate abate abate westward freedom affecting abate abate stern abate c demand means rather abate fate lease errd enter bay closet abate presume abate abate perfect abate performe abate abate follow joy abate unrest man wiry abate courtcubbord abate treads abate spring abate sea abate gore mouth hanging classdropicon abate boldness abate much abate vnbrused abate rosy abate torment easter lodging tomorrow abate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of Generated Text"
      ],
      "metadata": {
        "id": "oVefLq_pWIpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The basic LSTM model with only one layer trained quickly, but the output was not good. most of the words were mispelled or just a bunch of random letters and the sentences made no sense.\n",
        "*   Increasing the units in each LSTM layer also increased training time. However, using 128 units did produce better results than 64 units.\n",
        "*   Looking at the results of the generated text with .1 temperature, the word \"abate\" gets repeated a lot. The output is incoherent and lacks variety of words. The generated text for .5 temperature has a lot more variation in word choice. It is more creative but it is also incoherent because the text doesn't make any sense. Lastly, the text using 1.0 temperature shows the most creativity. The word \"abate\" is repeated less but many of the words seem made up. For example, in the output from the second prompt, words like \"valuesxclick\" appear that are not actual words. So while there is more variety, the text still lacks coherence.\n",
        "*   Overall, the model can form a lot of words that were used by Shakespeare, but the ordering is random. The generated text makes no sense because the model needs a lot more training. It has some of the basic vocabulary down, but needs more epochs in order to create phrases that are similar to Shakespeare's\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l1kVoKXmWJ_z"
      }
    }
  ]
}